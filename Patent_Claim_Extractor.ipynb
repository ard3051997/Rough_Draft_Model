{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Patent Claim Extractor.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "W76v-xN71gn6"
      },
      "source": [
        "!pip install google_patent_scraper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft5x9ssR87LW"
      },
      "source": [
        "import urllib.request as request\n",
        "import requests\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om51xjsC09E8"
      },
      "source": [
        "with open ('/HBSR.csv') as csv_file:\n",
        "  hbsr = pd.read_csv(\"/HBSR.csv\") \n",
        "  #csv_reader = csv.reader(csv_file)\n",
        "  csv_reader=hbsr['result link']\n",
        "  x = csv_reader.dropna() \n",
        "  a = []\n",
        "  for line, line2 in x.items():\n",
        "    #print(line2)\n",
        "    a.append(line2)\n",
        "\n",
        "  #print(a)\n",
        "  \n",
        "  for line in a:\n",
        "    \n",
        "  \n",
        "\n",
        "    r = requests.get(line)\n",
        "    #print(r)\n",
        "    soup = BeautifulSoup(r.content)\n",
        "    g_data = soup.find_all(\"div\", {\"class\":\"description\"})\n",
        "    with open('newpatentdata_class.csv', 'w', newline='', encoding=\"UTF-8\") as write_obj:\n",
        "    csv_writer = writer(write_obj)\n",
        "    for item in g_data:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSOLHZaLjKxv"
      },
      "source": [
        "print(g_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO89LlEy0TsJ"
      },
      "source": [
        "import csv\n",
        "import sys\n",
        "import re\n",
        "import datetime\n",
        "import google_patent_scraper\n",
        "import json\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "\n",
        "\n",
        "scraper = google_patent_scraper.scraper_class()\n",
        "   \n",
        "\n",
        "with open ('/HBSR.csv') as csv_file:\n",
        "  hbsr = pd.read_csv(\"/HBSR.csv\") \n",
        "  #csv_reader = csv.reader(csv_file)\n",
        "  csv_reader=hbsr['id']\n",
        "  #print(csv_reader.head())\n",
        "  a = []\n",
        "  i = 0\n",
        "  print(csv_reader.items())\n",
        "  for line, b in x.items():\n",
        "    print(b)\n",
        "    a.append(b)\n",
        "    \n",
        "\n",
        "    for row in a:\n",
        "      scraper.add_patents(row.replace(\"-\",\"\"))\n",
        "      i += 1\n",
        "        #if i == 5:\n",
        "        #    break\n",
        "    \n",
        "    scraper.scrape_all_patents()\n",
        "\n",
        "    pp = scraper.parsed_patents\n",
        "\n",
        "    if len(pp) < 10:\n",
        "        print(\"pp small\")\n",
        "    \n",
        "    for app_no in scraper.parsed_patents:\n",
        "        patent = scraper.parsed_patents[app_no]\n",
        "        got = False\n",
        "        for row in rows:\n",
        "            if app_no in row:\n",
        "                print(\"yay\")\n",
        "                got = True\n",
        "                row[\"CC\"] = patent[\"claims_count\"]\n",
        "                row[\"FCN\"] = len(patent[\"forward_cite_no_family\"])\n",
        "                row[\"FCY\"] = len(patent[\"forward_cite_yes_family\"])\n",
        "                print(row[\"CC\"])\n",
        "                print(row[\"FCN\"])\n",
        "                print(row[\"FCY\"])\n",
        "        if not got:\n",
        "            print(\"noooooooo\")\n",
        "\n",
        "with open('mod.txt', 'wt') as tsvfile:\n",
        "    tsv_writer = csv.writer(tsvfile, dialect='excel-tab')\n",
        "    \n",
        "    tsv_writer.writerow(reader.fieldnames + [\"CC\", \"FCN\", \"FCY\"])\n",
        "    for row in rows:\n",
        "        flat_row = []\n",
        "        for header in reader.fieldnames + [\"CC\", \"FCN\", \"FCY\"]:\n",
        "            if not header in [\"CC\", \"FCN\", \"FCY\"] or header in row:\n",
        "                flat_row.append(row[header])\n",
        "        tsv_writer.writerow(flat_row)\n",
        "     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Cfdi-s_GYxD"
      },
      "source": [
        "import unittest\n",
        "from patent_claim_text_converter import *\n",
        "\n",
        "sample_claim_text = \"1. A product tag system, comprising:\\\n",
        "an RFID tag adapted for attachment to a product;\\\n",
        "at least one data store in said tag for bar code information relating to said product;\\\n",
        "a tag detacher for removing said tag from said product at a point of sale;\\\n",
        "an RFID tag reader for retrieving said bar code information from said tag when said tag is placed in said tag detacher; and,\\\n",
        "a display for presenting said bar code information in a form which can be scanned by a conventional bar code scanner, said display associated with said tag detacher and said RFID tag reader at said point of sale.\\\n",
        "2. The system of claim 1, wherein said tag further comprises a detectable EAS element.\\\n",
        "3. The system of claim 1, wherein said tag detacher is inoperable for detaching said tag until said bar code information has been read.\\\n",
        "4. The system of claim 1, wherein said tag further comprises a further data store for further product information.\\\n",
        "5. The system of claim 1, further including a display for displaying human readable information related to said product.\\\n",
        "6. The system of claim 1, wherein said tag detacher is inoperable for detaching said tag until said tag detacher receives a confirmation signal that said bar code information has been successfully read by said bar code scanner.\\\n",
        "7. The system of claim 1, wherein said tag detacher comprises means for receiving a confirmation signal that said bar code information has been successfully read by said bar code scanner, said tag being detached responsive to said confirmation signal.\\\n",
        "8. The system of claim 1, wherein said tag detacher and said RFID tag reader are integrated in a single housing.\\\n",
        "9. The system of claim 1, wherein said tag detacher and said display are integrated in a single housing.\\\n",
        "10. The system of claim 9, wherein said single housing is adapted for mounting in a fixed position with respect to said conventional bar code scanner.\\\n",
        "11. The system of claim 1, wherein said display and said RFID tag reader are integrated in a single housing.\\\n",
        "12. The system of claim 11, wherein said single housing is adapted for mounting in a fixed position with respect to said conventional bar code scanner.\\\n",
        "13. The system of claim 11, wherein said single housing is adapted for mounting in a fixed position with respect to said conventional bar code scanner.\\\n",
        "14. The system of claim 11, wherein said tag detacher, said RFID tag reader and said display are integrated in a single housing.\\\n",
        "15. The system of claim 1, wherein said display is adapted for mounting in a fixed position with respect to said conventional bar code scanner.\\\n",
        "16. The system of claim 1, further comprising an RFID writer.\\\n",
        "17. The system of claim 16, wherein said tag comprises a further data store for receiving from said RFID writer information regarding said sale of said product, whereby said product sale information is available for subsequent use.\\\n",
        "18. A product tag system, comprising:\\\n",
        "an RFID tag adapted for attachment to a product;\\\n",
        "at least one data store in said tag for bar code information relating to said product;\\\n",
        "a tag detacher for removing said tag from said product at a point of sale;\\\n",
        "an RFID tag reader for retrieving said bar code information from said tag when said tag is placed in said tag detacher;\\\n",
        "a display for presenting said bat code information in a form which can be scanned by a conventional bar code scanner;\\\n",
        "a hand-held RFID reader adapted for attachment to a hand-held bar code scanner;\\\n",
        "a display on said hand-held RFID reader, said display being in an aligned position when said reader and said scanner are attached for presenting said bar code information in a form which can be scanned by said hand-held bar code scanner; and,\\\n",
        "a tag detacher remote from said reader for detaching said tag after said displayed bar code is scanned.\\\n",
        "19. The system of claim 18, wherein said tag detacher automatically detaches said tag responsive to a signal transmitted by said reader.\\\n",
        "20. A method for monitoring products, comprising the steps of:\\\n",
        "attaching an RFID tag to a product;\\\n",
        "writing bar code information onto said tag;\\\n",
        "retrieving said bar code information from said tag at a point of sale; and,\\\n",
        "displaying, at said point of sale, said bar code information in a form which can be scanned by a conventional bar code scanner at said point of sale.\\\n",
        "21. The method of claim 20, further comprising the step of activating a detectable EAS element in said tag prior to said retrieving step.\\\n",
        "22. The method of claim 21, wherein said attaching, writing and activating steps can occur in any order.\\\n",
        "23. The method of claim 20, further comprising the step of detaching said tag from said product.\\\n",
        "24. The method of claim 23, comprising the step of performing said retrieving, displaying and detaching steps with components disposed in a single housing.\\\n",
        "25. The method of claim 24, comprising the step of disposing said housing in a fixed position relative to said conventional bar code scanner.\\\n",
        "26. The method of claim 20, wherein said attaching and writing steps can occur in any order.\\\n",
        "27. The method of claim 20, further comprising the step of displaying said bar code information from a position fixed relative to said conventional bar code scanner.\\\n",
        "28. The method of claim 20, further comprising displaying said bar code information in human readable form.\\\n",
        "29. The method of claim 20, further comprising the step of writing to said tag, at said point of sale, information regarding said sale of said product, whereby said product sale information is available for subsequent use.\"\n",
        "\n",
        "sample_claim_text_1 = \"1. A product tag system, comprising:\\\n",
        "an RFID tag adapted for attachment to a product;\\\n",
        "at least one data store in said tag for bar code information relating to said product;\\\n",
        "a tag detacher for removing said tag from said product at a point of sale;\\\n",
        "an RFID tag reader for retrieving said bar code information from said tag when said tag is placed in said tag detacher; and,\\\n",
        "a display for presenting said bar code information in a form which can be scanned by a conventional bar code scanner, said display associated with said tag detacher and said RFID tag reader at said point of sale.\\\n",
        "2. The system of claim 1, wherein said tag further comprises a detectable EAS element.\"\n",
        "\n",
        "\n",
        "class PatentClaimTextConverterTest(unittest.TestCase):\n",
        "\n",
        "    def test_create_claim_marker(self):\n",
        "        self.assertEqual(create_claim_marker(1), '1.')\n",
        "        self.assertEqual(create_claim_marker(25), '25.')\n",
        "\n",
        "    def test_find_claim_numbers(self):\n",
        "        sample_claim_numbers = find_claim_numbers(sample_claim_text)\n",
        "        self.assertEqual(sample_claim_numbers[0], 0)\n",
        "        self.assertEqual(len(sample_claim_numbers), 29)\n",
        "\n",
        "    def test_json_conversion(self):\n",
        "        self.assertEqual(json.loads(convert_claim_text(sample_claim_text_1)), json.loads(\n",
        "            '{\\\n",
        "              \"1\": [\\\n",
        "                \"A product tag system, comprising:an RFID tag adapted for attachment to a product\",\\\n",
        "                \"at least one data store in said tag for bar code information relating to said product\",\\\n",
        "                \"a tag detacher for removing said tag from said product at a point of sale\",\\\n",
        "                \"an RFID tag reader for retrieving said bar code information from said tag when said tag is placed in said tag detacher\",\\\n",
        "                \" and,a display for presenting said bar code information in a form which can be scanned by a conventional bar code scanner, said display associated with said tag detacher and said RFID tag reader at said point of sale.\"\\\n",
        "              ],\\\n",
        "              \"2\": [\\\n",
        "                \"The system of claim 1, wherein said tag further comprises a detectable EAS element.\"\\\n",
        "              ]\\\n",
        "            }'\n",
        "        ))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhG-YlDyiWz8"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import pandas as pd "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFLM1wsWiT8M",
        "outputId": "a1c34801-635f-4ffd-bf1c-a0fc281f3c43"
      },
      "source": [
        "hbsr = pd.read_csv(\"/content/drive/MyDrive/DataforPatentDesign/D21C3-20ANDBoilingSolvent.csv\") \n",
        "#csv_reader = csv.reader(csv_file)\n",
        "print(hbsr)\n",
        "csv_reader=hbsr['result link']\n",
        "x = csv_reader.dropna() \n",
        "a = []\n",
        "for line, line2 in x.items():\n",
        "  #print(line2)\n",
        "  a.append(line2)\n",
        "print(a)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   id  ...                         representative figure link\n",
            "0    US-2020399722-A1  ...  https://patentimages.storage.googleapis.com/41...\n",
            "1    WO-2020245071-A1  ...                                                NaN\n",
            "2    WO-2020192432-A1  ...                                                NaN\n",
            "3     JP-2020063550-A  ...                                                NaN\n",
            "4       NL-2023946-B1  ...                                                NaN\n",
            "..                ...  ...                                                ...\n",
            "169      US-2022654-A  ...                                                NaN\n",
            "170      US-1975161-A  ...                                                NaN\n",
            "171      US-1856567-A  ...                                                NaN\n",
            "172       GB-340164-A  ...                                                NaN\n",
            "173      US-1633731-A  ...  https://patentimages.storage.googleapis.com/66...\n",
            "\n",
            "[174 rows x 10 columns]\n",
            "['https://patents.google.com/patent/US20200399722A1/en', 'https://patents.google.com/patent/WO2020245071A1/en', 'https://patents.google.com/patent/WO2020192432A1/en', 'https://patents.google.com/patent/JP2020063550A/en', 'https://patents.google.com/patent/NL2023946B1/en', 'https://patents.google.com/patent/US20200002888A1/en', 'https://patents.google.com/patent/CN110004756A/en', 'https://patents.google.com/patent/CN110128676A/en', 'https://patents.google.com/patent/US20190233596A1/en', 'https://patents.google.com/patent/EP3752582A1/en', 'https://patents.google.com/patent/DE102019001184A1/en', 'https://patents.google.com/patent/US20190153011A1/en', 'https://patents.google.com/patent/EP3724394A1/en', 'https://patents.google.com/patent/CN109535442A/en', 'https://patents.google.com/patent/AU2018217276B2/en', 'https://patents.google.com/patent/WO2019002553A1/en', 'https://patents.google.com/patent/CN108797176A/en', 'https://patents.google.com/patent/CA2999019A1/en', 'https://patents.google.com/patent/CN108360277A/en', 'https://patents.google.com/patent/CN109970872A/en', 'https://patents.google.com/patent/CN108330723A/en', 'https://patents.google.com/patent/CN108166294A/en', 'https://patents.google.com/patent/CN108149501A/en', 'https://patents.google.com/patent/CN108130795A/en', 'https://patents.google.com/patent/CN108149505A/en', 'https://patents.google.com/patent/WO2018114905A1/en', 'https://patents.google.com/patent/CN107201697B/en', 'https://patents.google.com/patent/US20180119344A1/en', 'https://patents.google.com/patent/KR20180133453A/en', 'https://patents.google.com/patent/CN108884187A/en', 'https://patents.google.com/patent/CN106400565A/en', 'https://patents.google.com/patent/CN106480766A/en', 'https://patents.google.com/patent/WO2017032926A2/en', 'https://patents.google.com/patent/US20180215893A1/en', 'https://patents.google.com/patent/CN106012654A/en', 'https://patents.google.com/patent/US10450698B2/en', 'https://patents.google.com/patent/WO2016172616A1/en', 'https://patents.google.com/patent/WO2016109466A1/en', 'https://patents.google.com/patent/EP3240869A1/en', 'https://patents.google.com/patent/CA2971733A1/en', 'https://patents.google.com/patent/WO2016109467A1/en', 'https://patents.google.com/patent/EP3240864A1/en', 'https://patents.google.com/patent/WO2016109474A1/en', 'https://patents.google.com/patent/CN107109245A/en', 'https://patents.google.com/patent/CN105332310A/en', 'https://patents.google.com/patent/EP3209829A1/en', 'https://patents.google.com/patent/WO2016053209A1/en', 'https://patents.google.com/patent/CN106795435A/en', 'https://patents.google.com/patent/CA2961401A1/en', 'https://patents.google.com/patent/WO2016053962A1/en', 'https://patents.google.com/patent/US20160369456A1/en', 'https://patents.google.com/patent/CN104988782A/en', 'https://patents.google.com/patent/CN104988783B/en', 'https://patents.google.com/patent/CN106661834A/en', 'https://patents.google.com/patent/DE102015006926A1/en', 'https://patents.google.com/patent/US20150225896A1/en', 'https://patents.google.com/patent/CN104695257A/en', 'https://patents.google.com/patent/EA029993B1/en', 'https://patents.google.com/patent/DE102014114534A1/en', 'https://patents.google.com/patent/WO2015021130A1/en', 'https://patents.google.com/patent/US10072099B2/en', 'https://patents.google.com/patent/US20150072389A1/en', 'https://patents.google.com/patent/WO2014179702A1/en', 'https://patents.google.com/patent/CN105358608B/en', 'https://patents.google.com/patent/WO2014179673A1/en', 'https://patents.google.com/patent/CN105339544A/en', 'https://patents.google.com/patent/EP2971190A1/en', 'https://patents.google.com/patent/EP2971336A1/en', 'https://patents.google.com/patent/EP2971335A1/en', 'https://patents.google.com/patent/EP2956465A1/en', 'https://patents.google.com/patent/CN104955848A/en', 'https://patents.google.com/patent/SE538671C2/en', 'https://patents.google.com/patent/US20140117277A1/en', 'https://patents.google.com/patent/US20140121418A1/en', 'https://patents.google.com/patent/WO2014060651A1/en', 'https://patents.google.com/patent/AU2013305911A1/en', 'https://patents.google.com/patent/US20140024093A1/en', 'https://patents.google.com/patent/SE1300378A1/en', 'https://patents.google.com/patent/EP2844796B1/en', 'https://patents.google.com/patent/WO2013162881A1/en', 'https://patents.google.com/patent/CN105283462A/en', 'https://patents.google.com/patent/CN104136579A/en', 'https://patents.google.com/patent/US8822657B2/en', 'https://patents.google.com/patent/US20130012610A1/en', 'https://patents.google.com/patent/WO2013005104A2/en', 'https://patents.google.com/patent/US20120264173A1/en', 'https://patents.google.com/patent/US20120184721A1/en', 'https://patents.google.com/patent/FI123768B/en', 'https://patents.google.com/patent/WO2012110231A1/en', 'https://patents.google.com/patent/US20120022240A1/en', 'https://patents.google.com/patent/CA2805451A1/en', 'https://patents.google.com/patent/US8030039B1/en', 'https://patents.google.com/patent/DE102010048614B4/en', 'https://patents.google.com/patent/CN102459293A/en', 'https://patents.google.com/patent/AU2010234084B8/en', 'https://patents.google.com/patent/WO2010071867A2/en', 'https://patents.google.com/patent/EP2225282A2/en', 'https://patents.google.com/patent/CN101680165A/en', 'https://patents.google.com/patent/US20100200182A1/en', 'https://patents.google.com/patent/CA2721460A1/en', 'https://patents.google.com/patent/FI122535B/en', 'https://patents.google.com/patent/CA2659015A1/en', 'https://patents.google.com/patent/US20070254348A1/en', 'https://patents.google.com/patent/US20070199669A1/en', 'https://patents.google.com/patent/BRPI0609594A2/en', 'https://patents.google.com/patent/CA2534619A1/en', 'https://patents.google.com/patent/US20040060673A1/en', 'https://patents.google.com/patent/FI115835B/en', 'https://patents.google.com/patent/EP1481124A1/en', 'https://patents.google.com/patent/CA2414928A1/en', 'https://patents.google.com/patent/CN100387774C/en', 'https://patents.google.com/patent/WO2001046520A1/en', 'https://patents.google.com/patent/DE10057878A1/en', 'https://patents.google.com/patent/DE19962411A1/en', 'https://patents.google.com/patent/DE69912007T2/en', 'https://patents.google.com/patent/US6251221B1/en', 'https://patents.google.com/patent/GB2329192A/en', 'https://patents.google.com/patent/EP1036236A1/en', 'https://patents.google.com/patent/WO1997049858A1/en', 'https://patents.google.com/patent/WO1997032075A1/en', 'https://patents.google.com/patent/RU2135665C1/en', 'https://patents.google.com/patent/FI103588B/en', 'https://patents.google.com/patent/CA2198485A1/en', 'https://patents.google.com/patent/WO1995021960A1/en', 'https://patents.google.com/patent/US5730837A/en', 'https://patents.google.com/patent/DE4343508A1/en', 'https://patents.google.com/patent/EP0593744A1/en', 'https://patents.google.com/patent/RU2084574C1/en', 'https://patents.google.com/patent/CN1082115A/en', 'https://patents.google.com/patent/US5382321A/en', 'https://patents.google.com/patent/JPH0551886A/en', 'https://patents.google.com/patent/EP0420771A1/en', 'https://patents.google.com/patent/EP0446556A1/en', 'https://patents.google.com/patent/FI92722C/en', 'https://patents.google.com/patent/US4767500A/en', 'https://patents.google.com/patent/US4742814A/en', 'https://patents.google.com/patent/CN86105219A/en', 'https://patents.google.com/patent/CA1217765B/en', 'https://patents.google.com/patent/US4597830A/en', 'https://patents.google.com/patent/EP0090969A1/en', 'https://patents.google.com/patent/DE3240725C2/en', 'https://patents.google.com/patent/EP0074983A1/en', 'https://patents.google.com/patent/FI71781B/en', 'https://patents.google.com/patent/US4470851A/en', 'https://patents.google.com/patent/NL8200241A/en', 'https://patents.google.com/patent/EP0041401B1/en', 'https://patents.google.com/patent/CA1147105A/en', 'https://patents.google.com/patent/EP0012960B1/en', 'https://patents.google.com/patent/FI69129C/en', 'https://patents.google.com/patent/SU1194282A3/en', 'https://patents.google.com/patent/CA1131415A/en', 'https://patents.google.com/patent/DE2857039C2/en', 'https://patents.google.com/patent/DE2803465A1/en', 'https://patents.google.com/patent/US4135967A/en', 'https://patents.google.com/patent/FI65290B/en', 'https://patents.google.com/patent/US3887426A/en', 'https://patents.google.com/patent/GB1386541A/en', 'https://patents.google.com/patent/US3715268A/en', 'https://patents.google.com/patent/OA3488A/en', 'https://patents.google.com/patent/ES351644A1/en', 'https://patents.google.com/patent/US3002877A/en', 'https://patents.google.com/patent/US2974067A/en', 'https://patents.google.com/patent/US2901389A/en', 'https://patents.google.com/patent/US2959500A/en', 'https://patents.google.com/patent/US2772968A/en', 'https://patents.google.com/patent/US2060068A/en', 'https://patents.google.com/patent/US2022664A/en', 'https://patents.google.com/patent/US2024689A/en', 'https://patents.google.com/patent/US2106797A/en', 'https://patents.google.com/patent/US2022654A/en', 'https://patents.google.com/patent/US1975161A/en', 'https://patents.google.com/patent/US1856567A/en', 'https://patents.google.com/patent/GB340164A/en', 'https://patents.google.com/patent/US1633731A/en']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTMnPf8bV4tr",
        "outputId": "b7892773-0e06-44bb-d570-8acdefd65228"
      },
      "source": [
        "c = a[:5]\n",
        "\n",
        "claim = []\n",
        "\n",
        "for line in c:\n",
        "  b = requests.get(line)\n",
        "  #print(r)\n",
        "  soup = BeautifulSoup(b.content)\n",
        "  g_data = soup.find_all(\"div\", {\"class\":\"claim-text\"})\n",
        "  #print(soup.prettify)   \n",
        "  #print(g_data[1])\n",
        "  ble = []\n",
        "  for d in g_data:\n",
        "    k = str(d.text)\n",
        "    ble.append(k)\n",
        "    #print(\"{}\\n\".format(k))\n",
        "\n",
        "print(ble)\n",
        "claim.append(ble)\n",
        "\n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\n 1. Werkwijze voor het scheiden van hemicellulose door efficiénte voorbehandeling van vezelige biomassa en volledig gebruikmaken hiervan, met het kenmerk, dat het houtkap- en verwerkingsresidu van vezelige biomassa als de grondstoffen wordt gebruikt, en voor behandeld door de suspensiewerkwijze door kogelmalen, watertoevoeging en roeren om een voorgemengde suspensieoplossing te verkrijgen die vezelachtig poeder van biomassamateriaal bevat; dat de houtvezels van de vezelige biomassamaterialen worden verwarmd om hydro thermische voorbehandeling te realiseren; dat, nadat de houtvezels zijn gefiltreerd, het filtraat wordt onderworpen aan gradiëntsedimentatie om hemicellulose met lage dispersiteit te verkrijgen, en de vloeistof wordt gedestilleerd om water te recyclen; dat nadat het filterresidu is gemengd met polair aprotisch oplosmiddel en water en gericht vloeibaar is gemaakt door reactie onder druk, de afgescheiden filterkoeken gefiltreerd worden, gewassen met water en gedroogd om zeer zuivere cellulose te verkrijgen; dat nadat aan het filtraat water is toegevoegd, dit is geroerd en met rust gelaten, dat lichtbruine, op lignine gebaseerde dissociatieve polyfenol wordt afgescheiden en gefiltreerd, gescheiden, gedroogd en opgeslagen, het filtraat onder verminderde druk wordt gedestilleerd om geleidelijk water en een kleine hoeveelheid bijproducten met kleine moleculen, dwz 5- hydroxymethyl furfural en furfural af te scheiden; dat het uiteindelijk resterende polaire aprotische oplosmiddel en water verkregen door fractionele scheiding in een bepaalde verhouding worden gemengd om te worden gerecycled; dat het gehalte aan hemicellulose in de vezelige biomassa groter 1s dan 20 gewichtsprocent.A method of separating hemicellulose by efficient pretreatment of fibrous biomass and making full use thereof, characterized in that the logging and processing residue of fibrous biomass is used as the raw materials, and pre-treated by the suspension process by ball milling, water addition and stirring to obtain a premixed suspension solution containing fibrous powder of biomass material; that the wood fibers of the fibrous biomass materials are heated to realize hydro-thermal pretreatment; that, after the wood fibers are filtered, the filtrate is subjected to gradient sedimentation to obtain low dispersity hemicellulose, and the liquid is distilled to recycle water; that after the filter residue is mixed with polar aprotic solvent and water and liquefied in a targeted manner by reaction under pressure, the separated filter cakes are filtered, washed with water and dried to obtain high-purity cellulose; that after water has been added to the filtrate, stirred and left alone, light brown lignin-based dissociative polyphenol is separated and filtered, separated, dried and stored, the filtrate is distilled under reduced pressure to gradually water and a small amount secrete small molecule by-products, ie 5-hydroxymethyl furfural and furfural; that the final remaining polar aprotic solvent and water obtained by fractional separation are mixed in a certain ratio to be recycled; that the hemicellulose content in the fibrous biomass is greater than 20% by weight. ', '\\n 2. Werkwijze voor het scheiden van hemicellulose door efficiénte voorbehandeling van vezelige biomassa en het volledig gebruiken daarvan volgens conclusie 1, waarbij de werkwijze de volgende stappen omvat: Stap 1: voorbehandeling met de suspensiewerkwijze: nadat het houtkap en verwerkingsresidu van de vezelige biomassamaterialen door een kogelmolen is samengedrukt, worden het verkregen vezelige biomassamateriaalpoeder en water gemengd en uniform geroerd bij kamertemperatuur om een voorgemengde oplossing te verkrijgen;A method for separating hemicellulose by efficient pretreatment of fibrous biomass and using it fully according to claim 1, wherein the method comprises the following steps: Step 1: pretreatment by the suspension process: after the logging and processing residue of the fibrous biomass materials has been passed through a ball mill is compressed, the obtained fibrous biomass material powder and water are mixed and stirred uniformly at room temperature to obtain a pre-mixed solution; ', '\\n 30 AO 19.10.1073 NL Stap 2: hydro thermische voorbehandeling: de voorgemengde oplossing wordt aangevuld met een bepaalde hoeveelheid water, geroerd en geleidelijk verwarmd tot 160-220 °C als voorbehandeling gedurende 20-120 minuten, en vervolgens afgekoeld tot kamertemperatuur en gefiltreerd; Stap 3: gradiéntsedimentatie en scheiding: aan het in stap 2 verkregen filtraat wordt bij kamertemperatuur absolute ethylalcohol toegevoegd en gefiltreerd nadat de centrifugale scheidingsreactie is voltooid, en de filterkoeken worden gewassen met ethylalcohol en gedroogd door vacuüm vriezen; de bovengenoemde bewerkingen worden herhaald om meer absolute ethylalcohol aan het filtraat toe te voegen, totdat het ethylalcoholgehalte 20% -75% bereikt; de verkregen filterkoeken zijn hemicellulose met lage dispersiteit en het filtraat wordt gerectificeerd om water en ethylalcohol te recyclen voor hergebruik; Stap 4: gerichte vloeibaarmaking en scheiding: het filterresidu verkregen in stap 2 wordt gemengd met complex oplosmiddel van het polaire aprotische oplosmiddel en water, geroerd en op een afgesloten manier verwarmd tot 140-240 °C voor voldoende reactie gedurende 10-180 minuten, en gefilterd nadat de reactie is voltooid, en de filterkoeken worden gewassen met water en gedroogd om zeer zuivere cellulose te verkrijgen; nadat water is toegevoegd aan het filtraat, dit is geroerd en met rust gelaten, wordt het afgescheiden, lichtbruine, op lignine gebaseerde dissociatieve polyfenol gefiltreerd, gescheiden, gedroogd en opgeslagen, het filtraat onder verminderde druk gedestilleerd om geleidelijk water en een kleine hoeveelheid bijproducten met kleine moleculen, dwz S-hydroxymethyl furfural en furfural af te scheiden; het uiteindelijke resterende polaire aprotische oplosmiddel en water verkregen door fractionele scheiding worden gemengd in een bepaalde verhouding om te worden gerecycled.30 AO 19.10.1073 NL Step 2: hydro-thermal pretreatment: the premixed solution is added with a certain amount of water, stirred and gradually heated to 160-220 ° C as pretreatment for 20-120 minutes, then cooled to room temperature and filtered; Step 3: Gradient sedimentation and separation: To the filtrate obtained in step 2, absolute ethyl alcohol is added at room temperature and filtered after the centrifugal separation reaction is completed, and the filter cakes are washed with ethyl alcohol and dried by vacuum freezing; the above operations are repeated to add more absolute ethyl alcohol to the filtrate until the ethyl alcohol content reaches 20% -75%; the resulting filter cakes are low dispersity hemicellulose and the filtrate is rectified to recycle water and ethyl alcohol for reuse; Step 4: Directed Liquefaction and Separation: The filter residue obtained in Step 2 is mixed with complex solvent of the polar aprotic solvent and water, stirred and heated in a sealed manner to 140-240 ° C for sufficient reaction for 10-180 minutes, and filtered after the reaction is completed, and the filter cakes are washed with water and dried to obtain high purity cellulose; After water is added to the filtrate, it is stirred and allowed to stand, the separated light brown lignin-based dissociative polyphenol is filtered, separated, dried and stored, the filtrate is distilled under reduced pressure to gradually dissolve water and a small amount of by-products. secrete small molecules, ie S-hydroxymethyl furfural and furfural; the final residual polar aprotic solvent and water obtained by fractional separation are mixed in a certain ratio to be recycled. ', '  3. Werkwijze voor het scheiden van hemicellulose door efficiënte voorbehandeling van vezelige biomassa en volledig gebruikmakend van dezelfde werkwijze volgens conclusie | of 2, waarbij in de suspensie-werkwijze voorbehandeling en de hydro thermische voorbehandeling de massaverhouding van het poeder van het vezelige biomassa materiaal poeder tot water 1 : 5-20 is. A method for separating hemicellulose by efficient pretreatment of fibrous biomass and using the same method according to claim | or 2, wherein in the slurry process pretreatment and the hydro thermal pretreatment, the mass ratio of the powder of the fibrous biomass material powder to water is 1: 5-20. ', '  31 AO 19.10.1073 NL 31 AO 19.10.1073 NL ', '\\n 4. Werkwijze voor het scheiden van hemicellulose door efficiënte voorbehandeling van vezelachtige biomassa en volledig gebruikmaken van deze werkwijze volgens conclusie 1 of 2, waarbij in het directionele vloeibaarmakingsproces de massaverhouding van de filterkoeken tot het complexe oplosmiddel van het polaire aprotische oplosmiddel en water 1 : 1-30 is.A method for separating hemicellulose by efficient pretreatment of fibrous biomass and making full use of this method according to claim 1 or 2, wherein in the directional liquefaction process, the mass ratio of the filter cakes to the complex solvent of the polar aprotic solvent and water is 1: 1 -30 is.\\n', '\\n 5. Werkwijze voor het scheiden van hemicellulose door efficiénte voorbehandeling van vezelachtige biomassa en het volledig gebruikmaken daarvan volgens conclusie 1 of 2, waarbij de massaverhouding van het polaire aprotische oplosmiddel tot water in het complexe oplosmiddelsysteem van het polaire aprotische oplosmiddel en water 9 : 1 is.A method for separating hemicellulose by efficient pretreatment of fibrous biomass and using it fully according to claim 1 or 2, wherein the mass ratio of the polar aprotic solvent to water in the complex solvent system of the polar aprotic solvent and water is 9: 1 .\\n', '\\n 6. Werkwijze voor het scheiden van hemicellulose door efficiënte voorbehandeling van vezelachtige biomassa en volledig gebruikmakend van dezelfde werkwijze volgens conclusie | of 2, waarbij het polaire aprotische oplosmiddel een sulfolaan, y- valerolacton, N, N-dimethylformamide, dimethylsulfoxide, tetrahydrofuran en 1,3- dimethyl-2-imidazolinon is.6. Process for separating hemicellulose by efficient pretreatment of fibrous biomass and fully using the same process according to claim | or 2, wherein the polar aprotic solvent is a sulfolane, γ-valerolactone, N, N-dimethylformamide, dimethyl sulfoxide, tetrahydrofuran and 1,3-dimethyl-2-imidazolinone.\\n', '\\n 7. Werkwijze voor het scheiden van hemicellulose door efficiënte voorbehandeling van vezelige biomassa en uitgebreid gebruik daarvan volgens conclusie 1 of 2, waarbij het gebruikte oplosmiddel en water beide kunnen worden gerecycled.A method for separating hemicellulose by efficient pretreatment of fibrous biomass and extensive use thereof according to claim 1 or 2, wherein the used solvent and water can both be recycled.\\n', '\\n 8. Werkwijze voor het scheiden van hemicellulose door efficiënte voorbehandeling van vezelige biomassa en volledig gebruikmakend van dezelfde werkwijze volgens conclusie 1 of 2, waarbij de vezelige biomassa bestaat uit papieren moerbei, maïskolf, wilg, katoenhout, berk, tarwestro, rijststro, katoen stengels en maïsstengels.A method for separating hemicellulose by efficient pretreatment of fibrous biomass and fully using the same method according to claim 1 or 2, wherein the fibrous biomass consists of paper mulberry, cob, willow, cottonwood, birch, wheat straw, rice straw, cotton stalks and corn stalks.\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xljZzI6sq6Pu",
        "outputId": "475e5b19-da8a-40ba-831c-74a1928dc8bc"
      },
      "source": [
        "hbsr['Claims'] = pd.Series(claim)\n",
        "print(hbsr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   id  ...                                             Claims\n",
            "0    US-2020399722-A1  ...  [\\n 1. Werkwijze voor het scheiden van hemicel...\n",
            "1    WO-2020245071-A1  ...                                                NaN\n",
            "2    WO-2020192432-A1  ...                                                NaN\n",
            "3     JP-2020063550-A  ...                                                NaN\n",
            "4       NL-2023946-B1  ...                                                NaN\n",
            "..                ...  ...                                                ...\n",
            "169      US-2022654-A  ...                                                NaN\n",
            "170      US-1975161-A  ...                                                NaN\n",
            "171      US-1856567-A  ...                                                NaN\n",
            "172       GB-340164-A  ...                                                NaN\n",
            "173      US-1633731-A  ...                                                NaN\n",
            "\n",
            "[174 rows x 11 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud-hoo0xwnd3"
      },
      "source": [
        "from styleframe import StyleFrame, Styler, utils\n",
        "StyleFrame(hbsr).to_excel(\"/content/drive/MyDrive/DataforPatentDesign/output_D21C3-20ANDBoilingSolvent.xlsx\", index=True).save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC6x0FM__G5W"
      },
      "source": [
        "!pip install styleframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yv3SEfG7yBZ"
      },
      "source": [
        "stringl = [\"bl kl kjk dnsjn asjnvkjs ncj\", \"saaaaaaaaaaaaaaaaaaaacc sssssssssssssssss\", \"aaaaaaaaaaaa fffffffffffffeeeeev vvvvvvvvvv\"]\n",
        "str5 = []\n",
        "for i in stringl:\n",
        "  str5.append(\"{} \\n\".format(i))\n",
        "str5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rwHEIuu_Pe8"
      },
      "source": [
        "df = pd.DataFrame([\n",
        "        ['First Line\\nSecond line'],\n",
        "        ['First line\\nsecond line\\nthird line'],\n",
        "        ['first line']\n",
        "    ])\n",
        "\n",
        "StyleFrame(df).to_excel('/content/drive/MyDrive/DataforPatentDesign/test.xlsx').save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egPxatvHx5YD",
        "outputId": "bbc1090a-0f89-40d0-ed06-db6a1118cc67"
      },
      "source": [
        "pip install scihub\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scihub\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/79/4f6d3136772b46d2647a8e9ad8b5bad39b2a387ac7ed1c12e854f8939c7a/scihub-0.0.1.tar.gz\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from scihub) (4.6.3)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from scihub) (2.23.0)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.7/dist-packages (from scihub) (1.3.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.11.1->scihub) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.11.1->scihub) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.11.1->scihub) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.11.1->scihub) (2020.12.5)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from retrying->scihub) (1.15.0)\n",
            "Building wheels for collected packages: scihub\n",
            "  Building wheel for scihub (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scihub: filename=scihub-0.0.1-cp37-none-any.whl size=4143 sha256=85467b91ca1f63bd9e3866a29ec48e2292372c4ca5b32e9403fa4f0511c01bce\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/06/34/4beb6f95c9f7dab6d5417b6af862daa64f3130cef6102d5be5\n",
            "Successfully built scihub\n",
            "Installing collected packages: scihub\n",
            "Successfully installed scihub-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "id": "pf_JEVYrMjxU",
        "outputId": "b59de4c3-0c7b-4bde-c259-5daad9d1aa9e"
      },
      "source": [
        "!pip install googlesearch-python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting googlesearch-python\n",
            "  Downloading https://files.pythonhosted.org/packages/e0/7d/c119eca9f9d3fc2f2919986bff4770fc313a06e6e295576379e7bbbf4b0f/googlesearch_python-2020.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: bs4==0.0.1 in /usr/local/lib/python3.7/dist-packages (from googlesearch-python) (0.0.1)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from googlesearch-python) (2.10)\n",
            "Collecting certifi==2020.6.20\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/c4/6c4fe722df5343c33226f0b4e0bb042e4dc13483228b4718baf286f86d87/certifi-2020.6.20-py2.py3-none-any.whl (156kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 11.7MB/s \n",
            "\u001b[?25hCollecting soupsieve==2.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.7/dist-packages (from googlesearch-python) (3.0.4)\n",
            "Collecting urllib3==1.25.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/e5/df302e8017440f111c11cc41a6b432838672f5a70aa29227bf58149dc72f/urllib3-1.25.9-py2.py3-none-any.whl (126kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 18.6MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.9.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/25/ff030e2437265616a1e9b25ccc864e0371a0bc3adb7c5a404fd661c6f4f6/beautifulsoup4-4.9.1-py3-none-any.whl (115kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 20.7MB/s \n",
            "\u001b[?25hCollecting requests==2.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.1MB/s \n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.24.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: certifi, soupsieve, urllib3, beautifulsoup4, requests, googlesearch-python\n",
            "  Found existing installation: certifi 2020.12.5\n",
            "    Uninstalling certifi-2020.12.5:\n",
            "      Successfully uninstalled certifi-2020.12.5\n",
            "  Found existing installation: soupsieve 2.2\n",
            "    Uninstalling soupsieve-2.2:\n",
            "      Successfully uninstalled soupsieve-2.2\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed beautifulsoup4-4.9.1 certifi-2020.6.20 googlesearch-python-2020.0.2 requests-2.24.0 soupsieve-2.0.1 urllib3-1.25.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "bs4",
                  "certifi",
                  "googlesearch",
                  "requests",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "RNeMbfVrNvCg",
        "outputId": "cbf83021-b11c-41ee-8195-60e65da0e5fe"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-eec8219a-afcd-4680-aba0-78bbfb736987\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-eec8219a-afcd-4680-aba0-78bbfb736987\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Input.csv to Input.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_Gw_1p2PXPF"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "train = pd.read_csv(io.StringIO(uploaded['Input.csv'].decode('utf-8')))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFp-pMNyQHL_"
      },
      "source": [
        "\n",
        "url = train['ArticleURL'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FnB7EnwFiWfW",
        "outputId": "42584cc8-b9fd-46d4-c0da-12c5e09a2697"
      },
      "source": [
        "url[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://www.sciencedirect.com/science/article/pii/S1359431117301400'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwCXg_JTRwGd"
      },
      "source": [
        "pip install scidownl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlxI72dhF9py"
      },
      "source": [
        "from scidownl.scihub import *\n",
        "\n",
        "DOI = url[1]\n",
        "out = 'paper'\n",
        "sci = SciHub(DOI, out).download(choose_scihub_url_index=3)\n",
        "\n",
        "#result = sh.fetch(url[1])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si_KgXbQPztg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtuyWmIWNqZI"
      },
      "source": [
        "from googlesearch import search\n",
        "search(a, num_results=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLviMSl-UgVk"
      },
      "source": [
        "!git clone https://github.com/gadilashashank/Sci-Hub.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR2KFp61UaxA"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "!sudo bash /content/Sci-Hub/configure.sh\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iQ-dYyBVUAn",
        "outputId": "64fc4ea6-8083-40dd-fb70-022cca098b24"
      },
      "source": [
        "!python3 /content/Sci-Hub/sci_hub.py "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trying primary method.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Sci-Hub/sci_hub.py\", line 185, in <module>\n",
            "    main()\n",
            "  File \"/content/Sci-Hub/sci_hub.py\", line 160, in main\n",
            "    sci_hub = validate_url(get_url())\n",
            "  File \"/content/Sci-Hub/sci_hub.py\", line 51, in get_url\n",
            "    return response.json()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/models.py\", line 898, in json\n",
            "    return complexjson.loads(self.text, **kwargs)\n",
            "  File \"/usr/lib/python3.7/json/__init__.py\", line 348, in loads\n",
            "    return _default_decoder.decode(s)\n",
            "  File \"/usr/lib/python3.7/json/decoder.py\", line 337, in decode\n",
            "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
            "  File \"/usr/lib/python3.7/json/decoder.py\", line 355, in raw_decode\n",
            "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
            "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJSEfnRjj6D2"
      },
      "source": [
        "path = \"/content/Sci-Hub/\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTZ0dZTslIWt"
      },
      "source": [
        "\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import platform\n",
        "import re\n",
        "import time\n",
        "import webbrowser as wbb\n",
        "\n",
        "# Python 2.x incompatibility\n",
        "if int(platform.python_version_tuple()[0]) < 3:\n",
        "    print(\"This script is NOT compatible with Python 2.x\")\n",
        "    print(\"Use this command to run the script:\\n\")\n",
        "    print(\"python3 sci_hub.py\\n\")\n",
        "    quit()\n",
        "\n",
        "# Warning for any platform other than *NIX\n",
        "if platform.system() not in ['Linux', 'Darwin']:\n",
        "    print(\"\\nYOU HAVE BEEN WARNED\")\n",
        "    print(\"Looks like you are not running on GNU/Linux or a Mac\")\n",
        "    print(\"This program is not guarenteed to work on Windows\\n\")\n",
        "\n",
        "from bs4 import BeautifulSoup as bs  # noqa: E402\n",
        "import requests  # noqa: E402\n",
        "\n",
        "# Download paper\n",
        "def download_paper(mirror):\n",
        "    # Response from mirror link\n",
        "    print(\"Sending request\")\n",
        "    response = requests.get(mirror)\n",
        "    print(\"Response received. Analyzing...\\n\")\n",
        "    # If header states PDF then write\n",
        "    # content to file\n",
        "    # Check if firefox exists and open download link\n",
        "    # in firefox\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "JCDccuS3nvFC",
        "outputId": "d297ac30-be4c-479f-d8a4-92707b1409e1"
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import platform\n",
        "import re\n",
        "import time\n",
        "import webbrowser as wbb\n",
        "\n",
        "# Python 2.x incompatibility\n",
        "if int(platform.python_version_tuple()[0]) < 3:\n",
        "    print(\"This script is NOT compatible with Python 2.x\")\n",
        "    print(\"Use this command to run the script:\\n\")\n",
        "    print(\"python3 sci_hub.py\\n\")\n",
        "    quit()\n",
        "\n",
        "# Warning for any platform other than *NIX\n",
        "if platform.system() not in ['Linux', 'Darwin']:\n",
        "    print(\"\\nYOU HAVE BEEN WARNED\")\n",
        "    print(\"Looks like you are not running on GNU/Linux or a Mac\")\n",
        "    print(\"This program is not guarenteed to work on Windows\\n\")\n",
        "\n",
        "from bs4 import BeautifulSoup as bs  # noqa: E402\n",
        "import requests  # noqa: E402\n",
        "\n",
        "# Define command line arguments\n",
        "parser = argparse.ArgumentParser(description=\"Sci-Hub downloader: Utility to \\\n",
        "                                             download from Sci-Hub\")\n",
        "parser.add_argument(\"target\",\n",
        "                    help=\"URL/DOI to download PDF\", type=str)\n",
        "parser.add_argument(\"--view\", help=\"Open article in browser for reading\",\n",
        "                    action=\"store_true\")\n",
        "args = parser.parse_args()\n",
        "\n",
        "\n",
        "args = {\n",
        "\t\"input\": \"path/to/input_image.jpg\",\n",
        "\t\"output\": \"path/to/output_image.jpg\"\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Get Sci-Hub URL from Google\n",
        "def get_url():\n",
        "    print(\"Trying primary method.\")\n",
        "    # Use where is sci hub now api service\n",
        "    response = requests.get(\"https://whereisscihub.now.sh/api\")\n",
        "    return response.json()\n",
        "\n",
        "# Alterane URL from Twitter\n",
        "def try_alternate():\n",
        "    print(\"Trying alternate method.\")\n",
        "    # Query twitter page of Sci-Hub\n",
        "    # and create soup object\n",
        "    response = requests.get(\"https://twitter.com/Sci_Hub\")\n",
        "    soup = bs(response.content, \"lxml\")\n",
        "    # Try to extract the URL present\n",
        "    # in the side panel as alt_url\n",
        "    for i in soup.find_all(\"a\", attrs={\"class\": \"u-textUserColor\"}):\n",
        "        # Regex check\n",
        "        if re.match('[http://[s]?]?sci-hub.[a-z]{2,}', i.text.strip()):\n",
        "            alt_url = i.text.strip()\n",
        "            # Append transfer protocol\n",
        "            # if not present\n",
        "            if \"://\" not in alt_url:\n",
        "                alt_url = \"https://\" + alt_url\n",
        "            print(\"Alternate URL is: \" + alt_url + \"\\n\")\n",
        "            return alt_url + \"/\"\n",
        "        else:\n",
        "            return \"\"\n",
        "\n",
        "\n",
        "# Validate URL by checking title\n",
        "def validate_url(url_list):\n",
        "    for url in url_list:\n",
        "        print(\"Validating {}\".format(url))\n",
        "        if url == \"\":\n",
        "            print(\"URL not valid\")\n",
        "        # Send request to given url\n",
        "        # and compare title tags\n",
        "        response = requests.get(url)\n",
        "        soup = bs(response.content, \"lxml\")\n",
        "        if soup.title.text == \"Sci-Hub: removing barriers in the way of science\":\n",
        "            print(\"{} validated\\n\".format(url))\n",
        "            if url[-1] != \"/\":\n",
        "                url += \"/\"\n",
        "            return url\n",
        "\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "# Extract DOI, Mirror\n",
        "def get_links(target):\n",
        "    # Get response of target page\n",
        "    # from Sci-Hub and create soup object\n",
        "    response = requests.get(target)\n",
        "    soup = bs(response.content, \"lxml\")\n",
        "    # Extract DOI\n",
        "    try:\n",
        "        mirror = soup.find(\"iframe\", attrs={\"id\": \"pdf\"})['src'].split(\"#\")[0]\n",
        "        if mirror.startswith('//'):\n",
        "            mirror = mirror[2:]\n",
        "            mirror = 'https://' + mirror\n",
        "    except Exception:\n",
        "        print(\"Mirror not found\")\n",
        "        mirror = \"\"\n",
        "    try:\n",
        "        doi = soup.title.text.split(\"|\")[2].strip()\n",
        "    except Exception:\n",
        "        print(\"DOI not found\")\n",
        "        doi = \"\"\n",
        "    # Extract download link\n",
        "    return doi, mirror\n",
        "\n",
        "\n",
        "# Download paper\n",
        "def download_paper(mirror, args):\n",
        "    # Response from mirror link\n",
        "    print(\"Sending request\")\n",
        "    response = requests.get(mirror)\n",
        "    print(\"Response received. Analyzing...\\n\")\n",
        "    # If header states PDF then write\n",
        "    # content to file\n",
        "    if args.view:\n",
        "        print(\"Firing up your browser...\")\n",
        "        wbb.open_new(mirror)\n",
        "        quit()\n",
        "    elif response.headers['content-type'] == \"application/pdf\":\n",
        "        size = round(int(response.headers['Content-Length'])/1000000, 2)\n",
        "        print(\"Downloaded {} MB\\n\".format(size))\n",
        "        with open(\"./Downloads/wuieobgefn.pdf\", \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "        f.close()\n",
        "    # Check if firefox exists and open download link\n",
        "    # in firefox\n",
        "    elif re.match(\"text/html\", response.headers['content-type']):\n",
        "        print(\"Looks like captcha encountered.\")\n",
        "        print(\"Download link is \\n\" + mirror + \"\\n\")\n",
        "        time.sleep(2)\n",
        "        wbb.open_new(mirror)\n",
        "        quit()\n",
        "\n",
        "\n",
        "# Rename and move\n",
        "def move_file(doi, args):\n",
        "    if doi:\n",
        "        name = doi.replace(\"/\", \"_\") + \".pdf\"\n",
        "        if os.path.exists(\"./Downloads/wuieobgefn.pdf\"):\n",
        "            os.rename(\"./Downloads/wuieobgefn.pdf\", \"./Downloads/\" + name)\n",
        "            print(\"Files saved at ./Downloads/\" + name)\n",
        "    else:\n",
        "        print(\"Files saved at ./Downloads/wuieobgefn.pdf\")\n",
        "\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    sci_hub = validate_url(get_url())\n",
        "    if not sci_hub:\n",
        "        sci_hub = validate_url(try_alternate())\n",
        "        if not sci_hub:\n",
        "            print(\"Sci-Hub mirror not found\")\n",
        "            print(\"Try after some time\")\n",
        "            quit()\n",
        "    else:\n",
        "        url = sci_hub + args.target\n",
        "        print(\"Extracting download links...\")\n",
        "        doi, mirror = get_links(url)\n",
        "        if not mirror:\n",
        "            print(\"Download link not available\")\n",
        "            print(\"Please try after sometime\")\n",
        "            print(\"\\nAlso try prepending ' http://dx.doi.org/' to input\")\n",
        "            print(\"If it still doesn't work raise an issue at \" +\n",
        "                  \"https://github.com/gadilashashank/Sci-Hub/issues\")\n",
        "            time.sleep(10)\n",
        "            quit()\n",
        "        else:\n",
        "            print(\"Downloading paper...\")\n",
        "            download_paper(mirror, args)\n",
        "            move_file(doi, args)\n",
        "\n",
        "\n",
        "main()\n",
        "print(\"\\nThanks for using.\\n\")\n",
        "quit()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--view] target\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Eie58T6mfpw",
        "outputId": "8b3d706b-3687-4bb2-c445-7b7d901cef8f"
      },
      "source": [
        "download_paper(\"https://sci-hub.se/https://www.sciencedirect.com/science/article/pii/S1359431117301400\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sending request\n",
            "Response received. Analyzing...\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_NLPLnzpEPo"
      },
      "source": [
        "from bs4 import BeautifulSoup as bs  # noqa: E402\n",
        "import requests  # noqa: E402"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbRR2OInpFOL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}